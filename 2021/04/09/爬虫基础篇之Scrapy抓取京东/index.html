<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="爬虫基础篇之Scrapy抓取京东"><meta name="keywords" content="scrapy,scrapy_redis,mongo"><meta name="author" content="J"><meta name="copyright" content="J"><title>爬虫基础篇之Scrapy抓取京东 | J</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?a345f534c85363668f09d4d5c6a9ee81";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>!function(e,a,t,n,g,c,o){e.GoogleAnalyticsObject=g,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),o=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",o.parentNode.insertBefore(c,o)}(window,document,"script",0,"ga"),ga("create","UA-111479568-4","auto"),ga("send","pageview")</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer="defer"></script><script>var GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容:${query}"}},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},hexoVersion:"4.1.1"}</script><meta name="generator" content="Hexo 4.1.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#虚拟环境"><span class="toc-number">1.</span> <span class="toc-text">虚拟环境</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#virtualenv"><span class="toc-number">1.1.</span> <span class="toc-text">virtualenv</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#virtualenvwrapper"><span class="toc-number">1.2.</span> <span class="toc-text">virtualenvwrapper</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy"><span class="toc-number">2.</span> <span class="toc-text">Scrapy</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#需求"><span class="toc-number">2.1.</span> <span class="toc-text">需求</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-抓取首页的分类信息"><span class="toc-number">2.1.1.</span> <span class="toc-text">1.1 抓取首页的分类信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-抓取商品信息"><span class="toc-number">2.1.2.</span> <span class="toc-text">1.2 抓取商品信息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实现"><span class="toc-number">2.2.</span> <span class="toc-text">实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型"><span class="toc-number">2.2.1.</span> <span class="toc-text">模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#类别模型"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">类别模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据模型"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">数据模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类爬虫"><span class="toc-number">2.2.2.</span> <span class="toc-text">分类爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#分析-分类信息的URL"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">分析, 分类信息的URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#创建爬虫-抓取数据"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">创建爬虫, 抓取数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#创建爬虫"><span class="toc-number">2.2.2.3.</span> <span class="toc-text">创建爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#指定起始URL"><span class="toc-number">2.2.2.4.</span> <span class="toc-text">指定起始URL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解析数据-交给引擎"><span class="toc-number">2.2.2.5.</span> <span class="toc-text">解析数据, 交给引擎</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#保存分类数据"><span class="toc-number">2.2.3.</span> <span class="toc-text">保存分类数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#商品爬虫"><span class="toc-number">2.2.4.</span> <span class="toc-text">商品爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#分析"><span class="toc-number">2.2.4.1.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代码实现"><span class="toc-number">2.2.4.2.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分布式"><span class="toc-number">2.2.4.3.</span> <span class="toc-text">分布式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#保存商品数据"><span class="toc-number">2.2.5.</span> <span class="toc-text">保存商品数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#反爬"><span class="toc-number">2.2.6.</span> <span class="toc-text">反爬</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#实现随机User-Agent的中间件"><span class="toc-number">2.2.6.1.</span> <span class="toc-text">实现随机User-Agent的中间件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实现代理IP中间件"><span class="toc-number">2.2.6.2.</span> <span class="toc-text">实现代理IP中间件</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://onejane.gitee.io/picture/avatar.jpg"></div><div class="author-info__name text-center">J</div><div class="author-info__description text-center">逆向,爬虫</div><div class="follow-button"><a href="https://github.com/OneJane/" target="_blank" rel="noopener">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">61</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">58</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">9</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/welggy" target="_blank" rel="noopener">OneJane</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image:url(http://onejane.gitee.io/picture/kali.jpg)"><div id="page-header"> <span class="pull-left"><a id="site-name" href="/">J</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i> <span class="pull-right menus"><a class="site-page" href="/">主页</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i> <span>搜索</span></a></span></div><div id="post-info"><div id="post-title">爬虫基础篇之Scrapy抓取京东</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-04-09</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/">爬虫基础</a><div class="post-meta-wordcount"><span>字数总计:</span> <span class="word-count">5.9k</span><span class="post-meta__separator">|</span><span>阅读时长: 28 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h1><p>同一台服务器上不同的项目可能依赖的包不同版本，新版本默认覆盖旧版本，可能导致其他项目无法运行，通过虚拟环境，完全隔离各个项目各个版本的依赖包，实现运行环境互不影响。</p><h2 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a>virtualenv</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenv		安装virtualenv</span><br><span class="line">python -m pip install --upgrade pip  升级pip</span><br><span class="line">pip install -i https:&#x2F;&#x2F;pypi.doubanio.com&#x2F;simple&#x2F; --trusted-host pypi.doubanio.com scrapy</span><br><span class="line">pip install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple  使用清华源</span><br><span class="line">pip uninstall scrapy    卸载django </span><br><span class="line">virtualenv scrapytest   默认环境创建虚拟环境</span><br><span class="line">cd scrapytest&#x2F;Scripts &amp;&amp;  activate.bat &amp;&amp; python 进入3.7虚拟环境</span><br><span class="line">virtualenv -p D:\Python27\python.exe scrapytest</span><br><span class="line">cd scrapytest&#x2F;Scripts &amp;&amp;  activate.bat &amp;&amp; python 进入2.7虚拟环境</span><br><span class="line">deactivate.bat          退出虚拟环境</span><br><span class="line"></span><br><span class="line">apt-get install python-virtualenv       安装虚拟环境</span><br><span class="line">virtualenv py2 &amp;&amp; cd py2 &amp;&amp; cd bin &amp;&amp; source activate &amp;&amp; python 进入2.7虚拟环境</span><br><span class="line">virtualenv -p &#x2F;usr&#x2F;bin&#x2F;python3 py3 &amp;&amp; &amp;&amp; cd py3 &amp;&amp; cd bin &amp;&amp; source activate &amp;&amp; python  进入3.7虚拟环境</span><br></pre></td></tr></table></figure><h2 id="virtualenvwrapper"><a href="#virtualenvwrapper" class="headerlink" title="virtualenvwrapper"></a>virtualenvwrapper</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenvwrapper</span><br><span class="line">pip install virtualenvwrapper-win	解决workon不是内部指令</span><br><span class="line">workon  列出所有虚拟环境</span><br><span class="line">新建环境变量   WORKON_HOME&#x3D;E:\envs</span><br><span class="line">mkvirtualenv py3scrapy  新建并进入虚拟环境</span><br><span class="line">deactivate          退出虚拟环境</span><br><span class="line">workon py3scrapy        进入指定虚拟环境</span><br><span class="line">    pip install -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple scrapy    安装scrapy源</span><br><span class="line">    若缺少lxml出错https:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs&#x2F;寻找对应版本的lxml的whl源</span><br><span class="line">    python -m pip install --upgrade pip     更新pip</span><br><span class="line">    pip install lxml-4.1.1-cp35-cp35m-win_amd64.whl</span><br><span class="line">    若缺少Twisted出错http:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs&#x2F;#lxml搜对应版本Twisted</span><br><span class="line">    pip install Twisted‑17.9.0‑cp35‑cp35m‑win_amd64.whl</span><br><span class="line">mkvirtualenv --python&#x3D;D:\Python27\python.exe py2scrapy      一般不会出问题</span><br><span class="line">    pip install -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple scrapy</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">pip install virtualenvwrapper    </span><br><span class="line">    find &#x2F; -name virualenvwrapper.sh</span><br><span class="line">    vim ~&#x2F;.bashrc</span><br><span class="line">        export WORKON_HOME&#x3D;$HOME&#x2F;.virtualenvs</span><br><span class="line">        source &#x2F;home&#x2F;wj&#x2F;.local&#x2F;bin&#x2F;virtualenvwrapper.sh</span><br><span class="line">    source ~&#x2F;.bashrc    </span><br><span class="line">mkvirtualenv py2scrapy          指向生成~&#x2F;.virtualenv</span><br><span class="line">deactivate          退出虚拟环境</span><br><span class="line">mkdirtualenv --python&#x3D;&#x2F;usr&#x2F;bin&#x2F;python3 py3scrapy</span><br><span class="line">rmvirtualenv py3scrapy  删除虚拟环境</span><br></pre></td></tr></table></figure><h1 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h1><p><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/%E4%BA%AC%E4%B8%9C%E5%85%A8%E7%BD%91%E7%88%AC%E8%99%AB.png" alt="京东全网爬虫"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple&#x2F; scrapy  安装scrapy</span><br><span class="line">scrapy startproject mall_spider  创建mall_spider项目</span><br><span class="line">scrapy genspider jd_category https:&#x2F;&#x2F;dc.3.cn&#x2F;category&#x2F;get  创建分类爬虫</span><br><span class="line">scrapy genspider --list  查看爬虫生成模板</span><br><span class="line">scrapy genspider -t crawl lagou www.lagou.com   创建全站爬虫</span><br><span class="line">pip freeze &gt; requirements.txt 生成依赖到文件</span><br><span class="line">pip install -r requirements.txt 一键安装依赖</span><br><span class="line">scrapy shell http:&#x2F;&#x2F;blog.jobbole.com&#x2F;       可以在脚本中调试xpath或者chrome浏览器右键copy xpath,chrome浏览器右键copy selector</span><br><span class="line">scrapy shell -s USER_AGENT&#x3D;&quot;Mozilla&#x2F;5.0 (Windows NT 6.1; WOW64; rv:51.0) Gecko&#x2F;20100101 Firefox&#x2F;51.0&quot; https:&#x2F;&#x2F;www.zhihu.com&#x2F;question&#x2F;56320032</span><br><span class="line">view(response)</span><br></pre></td></tr></table></figure><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><h3 id="1-1-抓取首页的分类信息"><a href="#1-1-抓取首页的分类信息" class="headerlink" title="1.1 抓取首页的分类信息"></a>1.1 抓取首页的分类信息</h3><ul><li>抓取数据: 各级分类的名称 和 URL<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/01_%E4%BA%AC%E4%B8%9C%E5%88%86%E7%B1%BB%E4%BF%A1%E6%81%AF.png"></li></ul><h3 id="1-2-抓取商品信息"><a href="#1-2-抓取商品信息" class="headerlink" title="1.2 抓取商品信息"></a>1.2 抓取商品信息</h3><ul><li><p>抓取: 商品名称, 商品价格, 商品评论数量, 商品店铺, 商品促销, 商品选项, 商品图片的URL<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/02_%E5%95%86%E5%93%81%E8%AF%A6%E6%83%85%E4%BF%A1%E6%81%AF.png"></p></li><li><p>由于全网爬虫, 抓取页面非常多, 为了提高抓的速度, 选择使用scrapy框架 + scrapy_redis分布式组件</p></li><li><p>由于京东全网的数据量达到了亿级, 存储又是结构化数据, 数据库, 选择使用MongoDB;</p></li></ul><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>我们采用广度优先策略, 我们把类别和商品信息的抓取分开来做.</p><p><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/image-20210422163642994.png" alt="image-20210422163642994"></p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><h4 id="类别模型"><a href="#类别模型" class="headerlink" title="类别模型"></a>类别模型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Category(scrapy.Item):</span><br><span class="line">    &quot;&quot;&quot;商品类别&quot;&quot;&quot;</span><br><span class="line">    # 大分类名称</span><br><span class="line">    b_category_name &#x3D; scrapy.Field()</span><br><span class="line">    # 大分类URL</span><br><span class="line">    b_category_url &#x3D; scrapy.Field()</span><br><span class="line">    # 中分类名称</span><br><span class="line">    m_category_name &#x3D; scrapy.Field()</span><br><span class="line">    # 中分类URL</span><br><span class="line">    m_category_url &#x3D; scrapy.Field()</span><br><span class="line">    # 小分类名称</span><br><span class="line">    s_category_name &#x3D; scrapy.Field()</span><br><span class="line">    # 小分类URL</span><br><span class="line">    s_category_url &#x3D; scrapy.Field()</span><br></pre></td></tr></table></figure><h4 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Product(scrapy.Item):</span><br><span class="line">    # 商品类别</span><br><span class="line">    product_category &#x3D; scrapy.Field()</span><br><span class="line">    # 商品ID</span><br><span class="line">    product_sku_id &#x3D; scrapy.Field()</span><br><span class="line">    # 商品名称</span><br><span class="line">    product_name &#x3D; scrapy.Field()</span><br><span class="line">    # 商品图片URL</span><br><span class="line">    product_img_url &#x3D; scrapy.Field()</span><br><span class="line">    # 商品店铺</span><br><span class="line">    product_shop &#x3D; scrapy.Field()</span><br><span class="line">    # 图书信息, 作者,出版社</span><br><span class="line">    product_book_info &#x3D; scrapy.Field()</span><br><span class="line">    # 商品选项</span><br><span class="line">    product_option &#x3D; scrapy.Field()</span><br><span class="line">    # 商品评论数量</span><br><span class="line">    product_comments &#x3D; scrapy.Field()</span><br><span class="line">    # 商品促销</span><br><span class="line">    product_ad &#x3D; scrapy.Field()</span><br><span class="line">    # 商品价格</span><br><span class="line">    product_price &#x3D; scrapy.Field()</span><br></pre></td></tr></table></figure><h3 id="分类爬虫"><a href="#分类爬虫" class="headerlink" title="分类爬虫"></a>分类爬虫</h3><h4 id="分析-分类信息的URL"><a href="#分析-分类信息的URL" class="headerlink" title="分析, 分类信息的URL"></a>分析, 分类信息的URL</h4><ul><li><code>目标</code>: <code>确定分类信息的URL</code></li><li><code>步骤</code>:<ol><li>进入到京东首页</li><li>右键检查, 打开开发者工具, 搜索 <code>家用电器</code></li><li>确定分类的URL</li></ol></li><li><code>图解</code>:<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/03_%E7%A1%AE%E5%AE%9A%E5%88%86%E7%B1%BB%E7%9A%84URL.png"></li><li><code>结论</code>:<ul><li>分类URL: <code>https://dc.3.cn/category/get</code></li></ul></li></ul><h4 id="创建爬虫-抓取数据"><a href="#创建爬虫-抓取数据" class="headerlink" title="创建爬虫, 抓取数据"></a>创建爬虫, 抓取数据</h4><ul><li><code>目标</code>: <code>抓取分类数据, 交给引擎</code></li><li><code>步骤</code>:<ol><li>创建类别爬虫</li><li>指定起始URL</li><li>解析数据, 交给引擎</li></ol></li></ul><h4 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h4><ul><li>进入项目目录: <code>cd mall_spider</code></li><li>创建爬虫: <code>scrapy genspider category_spider jd.com</code></li></ul><h4 id="指定起始URL"><a href="#指定起始URL" class="headerlink" title="指定起始URL"></a>指定起始URL</h4><ul><li>修改起始URL: <code>https://dc.3.cn/category/get</code></li></ul><h4 id="解析数据-交给引擎"><a href="#解析数据-交给引擎" class="headerlink" title="解析数据, 交给引擎"></a>解析数据, 交给引擎</h4><ul><li>分析数据格式:<ul><li>整体数据<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/05_1_%E6%95%B4%E4%BD%93%E5%88%86%E7%B1%BB%E6%A6%82%E5%86%B5.png"></li><li>各级分类位置<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/05_2_%E5%90%84%E7%BA%A7%E5%88%86%E7%B1%BB%E4%BD%8D%E7%BD%AE.png"></li><li>分类信息格式<ul><li>格式1:<ul><li><code>jiadian.jd.com|家用电器||0</code></li><li>特点: 第一项分类URL,第二项分类名称</li></ul></li><li>格式2:<ul><li><code>652-654|摄影摄像||0</code></li><li>对应的URL: <code>https://channel.jd.com/652-654.html</code></li><li>特点:第一项是频道ID, 包含一个 <code>-</code></li></ul></li><li>格式3:<ul><li><code>1318-2628-12131|户外风衣||0</code></li><li>对应URL: <code>https://list.jd.com/list.html?cat=1318,2628,12131</code></li><li>特点: 第一项为分类ID, 包含两个 <code>-</code></li></ul></li></ul></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">class JdCategorySpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;jd_category&#39;</span><br><span class="line">    allowed_domains &#x3D; [&#39;3.cn&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;https:&#x2F;&#x2F;dc.3.cn&#x2F;category&#x2F;get&#39;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # print(response.body.decode(&#39;GBK&#39;))</span><br><span class="line">        result &#x3D; json.loads(response.body.decode(&#39;GBK&#39;))</span><br><span class="line">        datas &#x3D; result[&#39;data&#39;]</span><br><span class="line">        # 遍历数据列表</span><br><span class="line">        for data in datas:</span><br><span class="line"></span><br><span class="line">            item &#x3D; Category()</span><br><span class="line"></span><br><span class="line">            b_category &#x3D; data[&#39;s&#39;][0]</span><br><span class="line">            b_category_info &#x3D; b_category[&#39;n&#39;]</span><br><span class="line">            # print(&#39;大分类: &#123;&#125;&#39;.format(b_category_info))</span><br><span class="line">            item[&#39;b_category_name&#39;], item[&#39;b_category_url&#39;] &#x3D; self.get_category_name_url(b_category_info)</span><br><span class="line"></span><br><span class="line">            # 中分类信息列表</span><br><span class="line">            m_category_s &#x3D; b_category[&#39;s&#39;]</span><br><span class="line">            # 遍历中分类列表</span><br><span class="line">            for m_category in m_category_s:</span><br><span class="line">                # 中分类信息</span><br><span class="line">                m_category_info &#x3D; m_category[&#39;n&#39;]</span><br><span class="line">                # print(&#39;中分类: &#123;&#125;&#39;.format(m_category_info))</span><br><span class="line">                item[&#39;m_category_name&#39;], item[&#39;m_category_url&#39;] &#x3D; self.get_category_name_url(m_category_info)</span><br><span class="line"></span><br><span class="line">                # 小分类数据列表</span><br><span class="line">                s_category_s &#x3D; m_category[&#39;s&#39;]</span><br><span class="line">                for s_category in s_category_s:</span><br><span class="line">                    s_category_info &#x3D; s_category[&#39;n&#39;]</span><br><span class="line">                    # print(&#39;小分类: &#123;&#125;&#39;.format(s_category_info))</span><br><span class="line">                    item[&#39;s_category_name&#39;], item[&#39;s_category_url&#39;] &#x3D; self.get_category_name_url(s_category_info)</span><br><span class="line">                    # print(item)</span><br><span class="line">                    # 把数据交给引擎</span><br><span class="line">                    yield item</span><br><span class="line"></span><br><span class="line">    def get_category_name_url(self, category_info):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        根据分类信息, 提取名称和URL</span><br><span class="line">        :param category_info:  分类信息</span><br><span class="line">        :return: 分类的名称和URL</span><br><span class="line">        分析数据格式(三类数据格式)</span><br><span class="line">        - book.jd.com&#x2F;library&#x2F;science.html|科学技术||0</span><br><span class="line">        - 1713-3287|计算机与互联网||0</span><br><span class="line">          - Https:&#x2F;&#x2F;channel.jd.com&#x2F;&#123;&#125;.html</span><br><span class="line">        - 9987-12854-12856|屏幕换新||0</span><br><span class="line">          - Https:&#x2F;&#x2F;list.jd.com&#x2F;list.html?cat&#x3D;&#123;&#125;</span><br><span class="line">          - 把 - 替换为逗号, 然后填充到占位的地方.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        category &#x3D; category_info.split(&#39;|&#39;)</span><br><span class="line">        # 分类URL</span><br><span class="line">        category_url &#x3D; category[0]</span><br><span class="line">        # 分类名称</span><br><span class="line">        category_name &#x3D; category[1]</span><br><span class="line"></span><br><span class="line">        # 处理第一类分类URL</span><br><span class="line">        if category_url.count(&#39;jd.com&#39;) &#x3D;&#x3D; 1:</span><br><span class="line">            # URL进行补全</span><br><span class="line">            category_url &#x3D; &#39;https:&#x2F;&#x2F;&#39; + category_url</span><br><span class="line">        elif category_url.count(&#39;-&#39;) &#x3D;&#x3D; 1:</span><br><span class="line">            # 1713-3287|计算机与互联网||0</span><br><span class="line">            category_url &#x3D; &#39;https:&#x2F;&#x2F;channel.jd.com&#x2F;&#123;&#125;.html&#39;.format(category_url)</span><br><span class="line">        else:</span><br><span class="line">            # 9987-12854-12856|屏幕换新||0</span><br><span class="line">            # 把URL中 &#96;-&#96; 替换为 &#96;,&#96;</span><br><span class="line">            category_url &#x3D; category_url.replace(&#39;-&#39;, &#39;,&#39;)</span><br><span class="line">            # 补全URL</span><br><span class="line">            category_url &#x3D; &#39;https:&#x2F;&#x2F;list.jd.com&#x2F;list.html?cat&#x3D;&#123;&#125;&#39;.format(category_url)</span><br><span class="line"></span><br><span class="line">        # 返回类别的名称 和 URL</span><br><span class="line">        return category_name, category_url</span><br></pre></td></tr></table></figure><h3 id="保存分类数据"><a href="#保存分类数据" class="headerlink" title="保存分类数据"></a>保存分类数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在settings.py开启, 类别的Pipeline</span><br><span class="line">ROBOTSTXT_OBEY &#x3D; False  不遵守网络协议</span><br><span class="line">ITEM_PIPELINES &#x3D; &#123;</span><br><span class="line">   &#39;mall_spider.pipelines.CategoryPipeline&#39;: 300,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>步骤</code>:</p><ol><li><code>open_spider</code>方法中, 链接MongoDB数据库, 获取要操作的集合</li><li><code>process_item</code> 方法中, 向MongoDB中插入类别数据</li><li><code>close_spider</code> 方法中, 关闭MongoDB的链接</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">实现保存分类的Pipeline类</span><br><span class="line">- open_spider方法中, 链接MongoDB数据库, 获取要操作的集合</span><br><span class="line">- process_item 方法中, 向MongoDB中插入类别数据</span><br><span class="line">- close_spider 方法中, 关闭MongoDB的链接</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">class CategoryPipeline(object):</span><br><span class="line"></span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        &quot;&quot;&quot;当爬虫启动的时候执行1次&quot;&quot;&quot;</span><br><span class="line">        if isinstance(spider, JdCategorySpider):</span><br><span class="line">            # open_spider方法中, 链接MongoDB数据库, 获取要操作的集合</span><br><span class="line">            self.client &#x3D; MongoClient(MONGODB_URL)</span><br><span class="line">            self.collection &#x3D; self.client[&#39;jd&#39;][&#39;category&#39;]</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        # process_item 方法中, 向MongoDB中插入类别数据</span><br><span class="line">        if isinstance(spider, JdCategorySpider):</span><br><span class="line">            self.collection.insert_one(dict(item))</span><br><span class="line"></span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        # close_spider 方法中, 关闭MongoDB的链接</span><br><span class="line">        if isinstance(spider, JdCategorySpider):</span><br><span class="line">            self.client.close()</span><br></pre></td></tr></table></figure><h3 id="商品爬虫"><a href="#商品爬虫" class="headerlink" title="商品爬虫"></a>商品爬虫</h3><p><code>总体设计</code>:</p><ol><li>把MongoDB中存储的分类信息, 放到redis_key指定列表中</li><li>支持分布式爬虫, 当然也可以在一台电脑上运行多次, 以启动多个进程,充分使用CPU的多核.</li><li>所以这里的爬虫, 先从一个分类开始抓就可以了, 后面再改造为分布式</li></ol><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><ul><li><p>列表页</p><ul><li><p>提取商品 skuid<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/07_1_%E4%BB%8E%E5%88%97%E8%A1%A8%E9%A1%B5%E6%88%96%E5%95%86%E5%93%81%E7%9A%84skuid.png"></p></li><li><p>实现翻页</p><ul><li>获取下一页URL<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/07_2_%E8%8E%B7%E5%8F%96%E5%88%86%E9%A1%B5%E7%9A%84URL.png"></li><li>没有下一页的情况<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/07_3_%E6%B2%A1%E6%9C%89%E4%B8%8B%E4%B8%80%E9%A1%B5%E7%9A%84%E6%83%85%E5%86%B5.png"></li></ul></li></ul></li><li><p>详情页<br>由于PC和手机页面商品信息, 在js中, 且比较分散, 并且每次请求数量页比较大, 我们这里使用手机抓包, 抓到json数据.</p></li><li><p>商品基本信息</p><ul><li>图:<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/08_1_%E5%95%86%E5%93%81%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF.png"></li><li>URL: <code>https://cdnware.m.jd.com/c1/skuDetail/apple/7.3.0/32426231880.json</code>; 最后一部分是商品skuid</li><li>可以获取到的信息: 商品名称, 商品店铺信息 , 商品类别id, 商品品牌id, 商品选项</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">  &#123;</span><br><span class="line"><span class="attr">"code"</span>: <span class="string">"0"</span>,</span><br><span class="line"><span class="attr">"wareInfo"</span>: &#123;</span><br><span class="line">	<span class="attr">"recommendInfo"</span>: &#123;</span><br><span class="line">		<span class="attr">"recommendList"</span>: <span class="literal">null</span></span><br><span class="line">	&#125;,</span><br><span class="line">      <span class="comment">// 商品店铺信息</span></span><br><span class="line">	<span class="attr">"shopInfo"</span>: &#123;</span><br><span class="line">		<span class="attr">"shop"</span>: &#123;</span><br><span class="line">			<span class="attr">"shopId"</span>: <span class="number">1000000127</span>,</span><br><span class="line">			<span class="attr">"name"</span>: <span class="string">"京东Apple产品专营店"</span>,</span><br><span class="line">		    ...</span><br><span class="line">		&#125;,	</span><br><span class="line">	"basicInfo": &#123;</span><br><span class="line">		"gift": false,</span><br><span class="line">		"bookInfo": &#123;</span><br><span class="line">              <span class="comment">// 如果是书, 这里是书的选项信息</span></span><br><span class="line">			"display": false</span><br><span class="line">		&#125;,</span><br><span class="line">	</span><br><span class="line">		"colorSizeInfo": &#123;</span><br><span class="line">              <span class="comment">// 商品选项信息列表 有的没有</span></span><br><span class="line">			"colorSize": [&#123;</span><br><span class="line">				"buttons": [&#123;</span><br><span class="line">					"no": "1",</span><br><span class="line">					"skuList": ["100000177738", "100000287117", "100000287145", "100000309448", "100000309450", "100000375233", "100000435832", "100000458753", "100000458755", "100001860767", "100001860773"],</span><br><span class="line">					"text": "金色"</span><br><span class="line">				&#125;, &#123;</span><br><span class="line">					"no": "2",</span><br><span class="line">					"skuList": ["100000177764", "100000287113", "100000287135", "100000435780", "100000435816", "100000435818", "100000569049", "100000602206", "100000602208", "100001860765", "100002539302"],</span><br><span class="line">					"text": "深空灰色"</span><br><span class="line">				&#125;, &#123;</span><br><span class="line">					"no": "3",</span><br><span class="line">					"skuList": ["100000177740", "100000177784", "100000287147", "100000435834", "100000458737", "100000458739", "100000602174", "100000602176", "100000602204", "100001860789", "100002539304"],</span><br><span class="line">					"text": "银色"</span><br><span class="line">				&#125;],</span><br><span class="line">				"title": "颜色"</span><br><span class="line">			&#125;, &#123;</span><br><span class="line">				"buttons": [&#123;</span><br><span class="line">					"no": "1",</span><br><span class="line">					"skuList": ["100000177738", "100000177740", "100000177764", "100000177784", "100000287113", "100000287117", "100000287135", "100000287145", "100000287147"],</span><br><span class="line">					"text": "公开版"</span><br><span class="line">				&#125;,</span><br><span class="line">                  ...</span><br><span class="line">                  ],</span><br><span class="line">				"title": "版本"</span><br><span class="line">			&#125;, &#123;</span><br><span class="line">				"buttons": [&#123;</span><br><span class="line">					"no": "1",</span><br><span class="line">					"skuList": ["100000177764", "100000287145", "100000287147", "100000375233", "100000435818", "100000458739", "100000458755", "100000602204", "100000602208", "100001860765", "100001860773", "100001860789"],</span><br><span class="line">					"text": "64GB"</span><br><span class="line">				&#125;, </span><br><span class="line">                  ...</span><br><span class="line">                  ],</span><br><span class="line">				"title": "内存"</span><br><span class="line">			&#125;],</span><br><span class="line">			"colorSizeTips": "#与其他已选项无法组成可售商品，请重选"</span><br><span class="line">		&#125;,</span><br><span class="line">	    ...</span><br><span class="line">          <span class="comment">// 品牌ID</span></span><br><span class="line">		"brandID": "14026",</span><br><span class="line">          ...</span><br><span class="line">          <span class="comment">// 商品图片</span></span><br><span class="line">		"wareImage": [&#123;</span><br><span class="line">			"small": "https://m.360buyimg.com/mobilecms/s720x720_jfs/t1/3/15/4536/138660/5b997bf8Ed72ebce7/819dcf182d743897.jpg!q70.jpg.webp",</span><br><span class="line">              ...</span><br><span class="line">		  &#125;</span><br><span class="line">            ...</span><br><span class="line">          ],</span><br><span class="line">          ...</span><br><span class="line">          <span class="comment">// 商品名称</span></span><br><span class="line">		"name": "Apple iPhone XS Max (A2104) 256GB 深空灰色 移动联通电信4G手机 双卡双待",</span><br><span class="line">          <span class="comment">// 商品类别id</span></span><br><span class="line">		"category": "9987;653;655"</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>商品促销信息(PC端):</p><ul><li>图:<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/08_2_%E5%95%86%E5%93%81%E8%AF%A6%E6%83%85%E8%8E%B7%E5%8F%96%E4%BF%83%E9%94%80%E4%BF%A1%E6%81%AF.png"></li><li>URL: <a href="https://cd.jd.com/promotion/v2?skuId=4749506&amp;area=1_72_4137_0&amp;cat=737,794,798" target="_blank" rel="noopener">https://cd.jd.com/promotion/v2?skuId=4749506&amp;area=1_72_4137_0&amp;cat=737%2C794%2C798</a><ul><li>参数<ul><li>skuId=4749506: 商品sku_id</li><li>area=1_72_4137_0: 购买者区域, 固定的</li><li>cat=737%2C794%2C798: 类别</li></ul></li></ul></li><li>数据</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 商品促销信息</span></span><br><span class="line">  "ads": [&#123;</span><br><span class="line">      "id": "AD_4749506",</span><br><span class="line">      "ad": "【即刻预约，21号秒杀到手价2999】\n1、前100名晒单送腾讯企鹅影院季卡，联系客服领取！！\n2、曲面爆款，5.5万好评推荐！&lt;a target=\"_blank\" href=\"https://item.jd.com/7055876.html\"&gt;升级55Q1D超清全面屏电视&lt;/a&gt;"</span><br><span class="line">  &#125;],</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>商品评论信息(PC端)</p><ul><li><p>图:<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/08_3_%E5%95%86%E5%93%81%E8%AF%84%E8%AE%BA%E4%BF%A1%E6%81%AFURL.png"></p></li><li><p>URL: <a href="https://club.jd.com/comment/productCommentSummaries.action?referenceIds=4749506" target="_blank" rel="noopener">https://club.jd.com/comment/productCommentSummaries.action?referenceIds=4749506</a></p><ul><li>参数<ul><li>referenceIds=4749506: 商品sku_id</li></ul></li></ul></li><li><p>数据:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"CommentsCount"</span>:[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"CommentCountStr"</span>:<span class="string">"10万+"</span>, </span><br><span class="line">        <span class="attr">"CommentCount"</span>:<span class="number">100000</span>, <span class="comment">//评论数量</span></span><br><span class="line">        <span class="attr">"AverageScore"</span>:<span class="number">5</span>,</span><br><span class="line">        <span class="attr">"GoodRate"</span>:<span class="number">0.98</span>, <span class="comment">//好评率</span></span><br><span class="line">        <span class="attr">"PoorCountStr"</span>:<span class="string">"600+"</span>, </span><br><span class="line">        <span class="attr">"PoorCount"</span>:<span class="number">600</span>, <span class="comment">// 差评数量</span></span><br><span class="line">        ...</span><br><span class="line">    &#125;]&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>商品价格信息:</p><ul><li><p>图:<br><img src="/2021/04/09/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8BScrapy%E6%8A%93%E5%8F%96%E4%BA%AC%E4%B8%9C/08_4_%E5%95%86%E5%93%81%E4%BB%B7%E6%A0%BCURL.png"></p></li><li><p>URL: <a href="https://p.3.cn/prices/mgets?skuIds=J_4749506" target="_blank" rel="noopener">https://p.3.cn/prices/mgets?skuIds=J_4749506</a></p><ul><li>参数:<ul><li>skuIds=J_4749506 商品的sku_id</li></ul></li></ul></li><li><p>数据:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">      <span class="attr">"op"</span>: <span class="string">"5499.00"</span>,</span><br><span class="line">      <span class="attr">"m"</span>: <span class="string">"5999.00"</span>,</span><br><span class="line">      <span class="attr">"id"</span>: <span class="string">"J_4749506"</span>, <span class="comment">//商品skuid</span></span><br><span class="line">      <span class="attr">"p"</span>: <span class="string">"3299.00"</span> <span class="comment">// 商品价格</span></span><br><span class="line">      &#125;</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><ul><li>步骤:<ol><li>重写start_requests方法, 根据分类信息构建列表页的请求</li><li>解析列表页, 提取商品的skuid, 构建商品基本的信息请求; 实现翻页</li><li>解析商品基本信息, 构建商品促销信息的请求</li><li>解析促销信息,构建商品评价信息的请求,</li><li>解析商品评价信息, 构建价格信息的请求</li><li>解析价格信息</li></ol></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">class JdProductSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;jd_product&#39;</span><br><span class="line">    allowed_domains &#x3D; [&#39;jd.com&#39;, &#39;p.3.cn&#39;]</span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        category &#x3D; &#123;  &quot;b_category_name&quot; : &quot;家用电器&quot;,</span><br><span class="line">                      &quot;b_category_url&quot; : &quot;https:&#x2F;&#x2F;jiadian.jd.com&quot;,</span><br><span class="line">                      &quot;m_category_name&quot; : &quot;洗衣机&quot;,</span><br><span class="line">                      &quot;m_category_url&quot; : &quot;https:&#x2F;&#x2F;list.jd.com&#x2F;list.html?cat&#x3D;737,794,880&quot;,</span><br><span class="line">                      &quot;s_category_name&quot; : &quot;洗衣机配件&quot;,</span><br><span class="line">                      &quot;s_category_url&quot; : &quot;https:&#x2F;&#x2F;list.jd.com&#x2F;list.html?cat&#x3D;737,794,877&quot; &#125;</span><br><span class="line"></span><br><span class="line">        yield scrapy.Request(category[&#39;s_category_url&#39;], self.parse, meta&#x3D;&#123;&#39;category&#39;: category&#125;)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # 获取类别信息</span><br><span class="line">        category &#x3D; response.meta[&#39;category&#39;]</span><br><span class="line">        # 获取类别的URL</span><br><span class="line">        category_url &#x3D; response.url.split(&#39;&amp;&#39;)[0]</span><br><span class="line">        # 获取所有商品的sku_ids</span><br><span class="line">        sku_ids &#x3D; response.xpath(&#39;&#x2F;&#x2F;div[contains(@class, &quot;j-sku-item&quot;)]&#x2F;@data-sku&#39;).extract()</span><br><span class="line">        # 遍历sku_ids, 构建基本详情信息的请求</span><br><span class="line">        for sku_id in sku_ids:</span><br><span class="line">            item &#x3D; &#123;</span><br><span class="line">                 &#39;product_category&#39;: category,</span><br><span class="line">                 &#39;product_sku_id&#39;:sku_id</span><br><span class="line">            &#125;</span><br><span class="line">            product_url &#x3D; &#39;https:&#x2F;&#x2F;cdnware.m.jd.com&#x2F;c1&#x2F;skuDetail&#x2F;apple&#x2F;7.3.0&#x2F;&#123;&#125;.json&#39;.format(sku_id)</span><br><span class="line">            yield scrapy.Request(product_url, callback&#x3D;self.parse_product, meta&#x3D;&#123;&#39;item&#39;: item&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        # 获取下一页的URL</span><br><span class="line">        next_url &#x3D; response.xpath(&#39;&#x2F;&#x2F;a[@class&#x3D;&quot;pn-next&quot;]&#x2F;@href&#39;).extract_first()</span><br><span class="line">        if next_url:</span><br><span class="line">            # 补全URL</span><br><span class="line">            next_url &#x3D; response.urljoin(next_url)</span><br><span class="line">            # 构建下一页请求</span><br><span class="line">            yield scrapy.Request(next_url, callback&#x3D;self.parse, meta&#x3D;&#123;&#39;category&#39;: category&#125;)</span><br><span class="line"></span><br><span class="line">    def parse_product(self, response):</span><br><span class="line">        # 取出传递过来的数据</span><br><span class="line">        item &#x3D; response.meta[&#39;item&#39;]</span><br><span class="line">        # 把响应数据数据转为字典</span><br><span class="line">        product_dic &#x3D; json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        # 获取商品名称</span><br><span class="line">        item[&#39;product_name&#39;] &#x3D; product_dic[&#39;wareInfo&#39;][&#39;basicInfo&#39;][&#39;name&#39;]</span><br><span class="line">        if  item[&#39;product_name&#39;]:</span><br><span class="line">            # 获取类别id, 把 &#96;;&#96; 替换为 ,</span><br><span class="line">            item[&#39;product_category_id&#39;] &#x3D; product_dic[&#39;wareInfo&#39;][&#39;basicInfo&#39;][&#39;category&#39;].replace(&#39;;&#39;, &#39;,&#39;)</span><br><span class="line">            # 获取店铺信息</span><br><span class="line">            product_shop &#x3D; jsonpath(product_dic, &#39;$..shop&#39;)</span><br><span class="line">            if product_shop:</span><br><span class="line">                product_shop &#x3D; product_shop[0]</span><br><span class="line">                if product_shop is None:</span><br><span class="line">                    item[&#39;product_shop&#39;] &#x3D; &#123;&#39;name&#39;:&#39;京东自营&#39;&#125;</span><br><span class="line">                else:</span><br><span class="line">                    item[&#39;product_shop&#39;] &#x3D; &#123;</span><br><span class="line">                        &quot;shopId&quot;: product_shop[&#39;shopId&#39;],</span><br><span class="line">                        &quot;name&quot;: product_shop[&#39;name&#39;],</span><br><span class="line">                        &quot;score&quot;: product_shop[&#39;score&#39;],</span><br><span class="line">                        &quot;url&quot;: product_shop[&#39;url&#39;],</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">            # 如果是书, 记录书的信息</span><br><span class="line">            if product_dic[&#39;wareInfo&#39;][&#39;basicInfo&#39;][&#39;bookInfo&#39;][&#39;display&#39;]:</span><br><span class="line">                item[&#39;product_book_info&#39;] &#x3D; product_dic[&#39;wareInfo&#39;][&#39;basicInfo&#39;][&#39;bookInfo&#39;]</span><br><span class="line">                # 删除display</span><br><span class="line">                del item[&#39;book_info&#39;][&#39;display&#39;]</span><br><span class="line">            # 获取商品选购信息</span><br><span class="line">            color_sizes &#x3D; jsonpath(product_dic, &#39;$..colorSize&#39;)</span><br><span class="line">            product_option &#x3D; &#123;&#125;</span><br><span class="line">            if color_sizes:</span><br><span class="line">                for color_size in color_sizes[0]:</span><br><span class="line">                    title &#x3D; color_size[&#39;title&#39;]</span><br><span class="line">                    texts &#x3D; jsonpath(color_size, &#39;$..text&#39;)</span><br><span class="line">                    product_option.update(&#123;title:texts&#125;)</span><br><span class="line">                    # print(product_option)</span><br><span class="line">            item[&#39;product_option&#39;] &#x3D; product_option</span><br><span class="line">            # 商品图片</span><br><span class="line">            item[&#39;product_img_url&#39;] &#x3D; jsonpath(product_dic, &#39;$..wareImage[0].small&#39;)[0]</span><br><span class="line"></span><br><span class="line">            # 构建促销信息的请求</span><br><span class="line">            ad_url &#x3D; &#39;https:&#x2F;&#x2F;cd.jd.com&#x2F;promotion&#x2F;v2?skuId&#x3D;&#123;&#125;&amp;area&#x3D;1_72_4137_0&amp;cat&#x3D;&#123;&#125;&#39;.format(item[&#39;product_sku_id&#39;], item[&#39;product_category_id&#39;])</span><br><span class="line">            yield scrapy.Request(ad_url, callback&#x3D;self.parse_ad, meta&#x3D;&#123;&#39;item&#39;: item&#125;)</span><br><span class="line"></span><br><span class="line">    def parse_ad(self, response):</span><br><span class="line">        &quot;&quot;&quot;获取商品促销&quot;&quot;&quot;</span><br><span class="line">        item &#x3D; response.meta[&#39;item&#39;]</span><br><span class="line">        ad_dic &#x3D; json.loads(response.body.decode(&#39;GB18030&#39;))</span><br><span class="line">        ad &#x3D;  ad_dic[&#39;ads&#39;][0][&#39;ad&#39;]</span><br><span class="line">        item[&#39;product_ad&#39;] &#x3D; ad</span><br><span class="line"></span><br><span class="line">        # for key, value in item.items():</span><br><span class="line">        #     print(&#39;&#123;&#125; &#x3D; &#123;&#125;&#39;.format(key, value))</span><br><span class="line"></span><br><span class="line">        # 构建平均信息请求</span><br><span class="line">        comments_url &#x3D; &#39;https:&#x2F;&#x2F;club.jd.com&#x2F;comment&#x2F;productCommentSummaries.action?referenceIds&#x3D;&#123;&#125;&#39;.format(item[&#39;product_sku_id&#39;])</span><br><span class="line">        yield scrapy.Request(comments_url, callback&#x3D;self.parse_comments, meta&#x3D;&#123;&#39;item&#39;: item&#125;)</span><br><span class="line"></span><br><span class="line">    def parse_comments(self, response):</span><br><span class="line">        &quot;&quot;&quot;解析商品评论信息&quot;&quot;&quot;</span><br><span class="line">        item &#x3D; response.meta[&#39;item&#39;]</span><br><span class="line">        comments_dic &#x3D; json.loads(response.text)</span><br><span class="line">        comments &#x3D; &#123;</span><br><span class="line">            &#39;comment_count&#39;: jsonpath(comments_dic, &#39;$..CommentCount&#39;)[0],</span><br><span class="line">            &#39;good_rate&#39;: jsonpath(comments_dic, &#39;$..GoodRate&#39;)[0],</span><br><span class="line">            &#39;poor_count&#39;: jsonpath(comments_dic, &#39;$..PoorCount&#39;)[0],</span><br><span class="line">        &#125;</span><br><span class="line">        item[&#39;product_comments&#39;] &#x3D; comments</span><br><span class="line">        # print(item)</span><br><span class="line">        # 构建价格请求</span><br><span class="line">        price_url &#x3D; &#39;https:&#x2F;&#x2F;p.3.cn&#x2F;prices&#x2F;mgets?skuIds&#x3D;J_&#123;&#125;&#39;.format(item[&#39;product_sku_id&#39;])</span><br><span class="line">        yield scrapy.Request(price_url, callback&#x3D;self.parse_price, meta&#x3D;&#123;&#39;item&#39;: item&#125;)</span><br><span class="line"></span><br><span class="line">    def parse_price(self, response):</span><br><span class="line">        &quot;&quot;&quot;解析价格&quot;&quot;&quot;</span><br><span class="line">        item &#x3D; response.meta[&#39;item&#39;]</span><br><span class="line">        item[&#39;product_price&#39;] &#x3D; json.loads(response.text)[0][&#39;p&#39;]</span><br><span class="line">        # print(item)</span><br><span class="line">        yield item</span><br></pre></td></tr></table></figure><h4 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h4><ul><li><code>步骤</code>:<ol><li>修改爬虫类</li><li>在settings文件中配置scrapy_redis</li><li>写一个程序用于把MongoDB中分类信息, 放入到爬虫redis_key指定的列表中</li></ol></li></ul><p><strong>修改爬虫类</strong></p><ul><li><code>步骤</code>:<ol><li>修改继承关系: 继承RedisSpider</li><li>指定redis_key</li><li>把重写start_requests 改为 重写 make_request_from_data</li></ol></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from scrapy_redis.spiders import RedisSpider</span><br><span class="line">import pickle</span><br><span class="line"></span><br><span class="line">#  1. 修改继承关系: 继承RedisSpider</span><br><span class="line">class JdProductSpider(RedisSpider):</span><br><span class="line">    name &#x3D; &#39;jd_product&#39;</span><br><span class="line">    allowed_domains &#x3D; [&#39;jd.com&#39;, &#39;p.3.cn&#39;]</span><br><span class="line">    # 2. 指定redis_key</span><br><span class="line">    redis_key &#x3D; &#39;jd_product:start_category&#39;</span><br><span class="line"></span><br><span class="line">    # 3. 把重写start_requests 改为 重写 make_request_from_data</span><br><span class="line">    def make_request_from_data(self, data):</span><br><span class="line">        # 把从Redis中读取到分类信息, 转换为字典</span><br><span class="line">        category &#x3D; pickle.loads(data)</span><br><span class="line">        return scrapy.Request(category[&#39;s_category_url&#39;], self.parse, meta&#x3D;&#123;&#39;category&#39;: category&#125;)</span><br></pre></td></tr></table></figure><p><code>注意</code>: 在<code>make_request_from_data</code>不能使用 <code>yield</code> 必须使用 <code>return</code></p><p><strong>在settings文件中配置scrapy_redis</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># MongoDB数据库的URL</span><br><span class="line">MONGO_URL &#x3D; &#39;mongodb:&#x2F;&#x2F;127.0.0.1:27017&#39;</span><br><span class="line"></span><br><span class="line"># REDIS数据链接</span><br><span class="line">REDIS_URL &#x3D; &#39; redis:&#x2F;&#x2F;127.0.0.1:6379&#x2F;0&#39;</span><br><span class="line"></span><br><span class="line"># 去重容器类: 用于把已爬指纹存储到基于Redis的set集合中</span><br><span class="line">DUPEFILTER_CLASS &#x3D; &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span><br><span class="line"># 调度器: 用于把待爬请求存储到基于Redis的队列</span><br><span class="line">SCHEDULER &#x3D; &quot;scrapy_redis.scheduler.Scheduler&quot;</span><br><span class="line"># 是不进行调度持久化:</span><br><span class="line"># 如果是True, 当程序结束的时候, 会保留Redis中已爬指纹和待爬的请求</span><br><span class="line"># 如果是False, 当程序结束的时候, 会清空Redis中已爬指纹和待爬的请求</span><br><span class="line">SCHEDULER_PERSIST &#x3D; True</span><br></pre></td></tr></table></figure><p><strong>把MongoDB中分类信息, 放入到爬虫redis_key指定的列表中</strong></p><ul><li><p><code>步骤</code>:</p><ul><li><ol><li>在项目文件夹下创建 <code>add_category_to_redis.py</code></li></ol></li><li><ol start="2"><li>实现方法 <code>add_category_to_redis</code>:<ol><li>链接MongoDB</li><li>链接Redis</li><li>读取MongoDB中分类信息, 序列化后, 添加到商品爬虫redis_key指定的list</li><li>关闭MongoDB</li></ol></li></ol></li><li><ol start="3"><li>在<code>if __name__ == &#39;__main__&#39;:</code>中调用<code>add_category_to_redis</code>方法</li></ol></li></ul></li><li><p><code>代码</code></p></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> StrictRedis</span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mall_spider.settings <span class="keyword">import</span> MONGO_URL, REDIS_URL</span><br><span class="line"><span class="keyword">from</span> mall_spider.spiders.jd_product <span class="keyword">import</span> JdProductSpider</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把MongoDB中分类信息, 添加到Redis中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_category_to_redis</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 链接MongoDB</span></span><br><span class="line">    client = MongoClient(MONGO_URL)</span><br><span class="line">    <span class="comment"># 链接Redis</span></span><br><span class="line">    redis = StrictRedis.from_url(REDIS_URL)</span><br><span class="line"></span><br><span class="line">    cursor = client[<span class="string">'jd'</span>][<span class="string">'category'</span>].find()</span><br><span class="line">    <span class="comment"># 读取MongoDB中分类信息, 序列化后, 添加到商品爬虫redis_key指定的list</span></span><br><span class="line">    <span class="keyword">for</span> category <span class="keyword">in</span> cursor:</span><br><span class="line">        redis.rpush(JdProductSpider.redis_key, pickle.dumps(category))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 关闭MongoDB的链接</span></span><br><span class="line">    client.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    add_category_to_redis()</span><br></pre></td></tr></table></figure><h3 id="保存商品数据"><a href="#保存商品数据" class="headerlink" title="保存商品数据"></a>保存商品数据</h3><p><code>步骤</code></p><ul><li><p>在 open_spider方法, 建立MongoDB数据库连接, 获取要操作的集合</p></li><li><p>在 process_item方法, 把数据插入到MongoDB中</p></li><li><p>在close_spider方法, 关闭数据库连接</p></li><li><p>代码</p></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProductPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(spider, JdProductSpider):</span><br><span class="line">            <span class="comment"># 建立MongoDB数据库链接</span></span><br><span class="line">            self.client = MongoClient(MONGO_URL)</span><br><span class="line">            <span class="comment"># 获取要操作集合</span></span><br><span class="line">            self.category = self.client[<span class="string">'jd'</span>][<span class="string">'product'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(spider, JdProductSpider):</span><br><span class="line">            <span class="comment"># 把数据插入到mongo中</span></span><br><span class="line">            self.category.insert_one(dict(item))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""关闭"""</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(spider, JdProductSpider):</span><br><span class="line">            self.client.close()</span><br></pre></td></tr></table></figure><p><strong>在settings.py中开启这个管道</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'mall_spider.pipelines.CategoryPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="comment"># 开启商品管道</span></span><br><span class="line">   <span class="string">'mall_spider.pipelines.ProductPipeline'</span>: <span class="number">301</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="反爬"><a href="#反爬" class="headerlink" title="反爬"></a>反爬</h3><p>为了避免IP反爬, 我们实现随机User-Agent和代理IP的中间件</p><ul><li><code>步骤</code>:<ol><li>实现随机User-Agent的中间件</li><li>实现代理IP中间件</li><li>在settings.py 文件开启, 下载器中间件</li></ol></li></ul><h4 id="实现随机User-Agent的中间件"><a href="#实现随机User-Agent的中间件" class="headerlink" title="实现随机User-Agent的中间件"></a>实现随机User-Agent的中间件</h4><ul><li><p><code>步骤</code></p><ul><li>准备User-Agent列表</li><li>在middlewares.py中, 实现RandomUserAgent类</li><li>实现process_request方法<ul><li>如果是请求是 <code>https://cdnware.m.jd.com</code> 开头的, 就是设置一个iPhone的user-agent</li><li>否则从User-Agent列表中随机取出一个</li></ul></li></ul></li><li><p>代码</p></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备请求头</span></span><br><span class="line">USER_AGENTS = [</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20"</span>,</span><br><span class="line">    <span class="string">"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 LBBROWSER"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; 360SE)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (iPad; U; CPU OS 4_2_1 like Mac OS X; zh-cn) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8C148 Safari/6533.18.5"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0b13pre) Gecko/20110307 Firefox/4.0b13pre"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:16.0) Gecko/20100101 Firefox/16.0"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11"</span>,</span><br><span class="line">    <span class="string">"Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10"</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgent</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> request.url.startswith(<span class="string">'https://cdnware.m.jd.com'</span>):</span><br><span class="line">            <span class="comment"># 如果使用手机抓包, 获取到商品信息; 生成请求请求头</span></span><br><span class="line">            request.headers[<span class="string">'user-agent'</span>] = <span class="string">'JD4iPhone/164880 (iPhone; iOS 12.1.2; Scale/2.00)'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 随机获取一个请求头, 进行设置</span></span><br><span class="line">            request.headers[<span class="string">'user-agent'</span>] = random.choice(USER_AGENTS)</span><br></pre></td></tr></table></figure><h4 id="实现代理IP中间件"><a href="#实现代理IP中间件" class="headerlink" title="实现代理IP中间件"></a>实现代理IP中间件</h4><ul><li><p><code>步骤</code>:</p><ul><li>在middlewares.py中, 实现ProxyMiddleware类</li><li>实现process_request方法<ul><li>从代理池中获取一个随机的代理IP, 需指定代理IP的协议, 和访问的域名</li><li>设置给request.meta[‘proxy’]</li></ul></li><li>实现process_exception方法</li><li>当请求出现异常的时候, 代理池哪些代理IP在本域名下是不可以用的</li></ul></li><li><p><code>代码</code></p></li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">9.2. 实现代理IP中间件</span></span><br><span class="line"><span class="string">步骤:</span></span><br><span class="line"><span class="string">    在middlewares.py中, 实现ProxyMiddleware类</span></span><br><span class="line"><span class="string">    实现process_request方法</span></span><br><span class="line"><span class="string">    从代理池中获取一个随机的代理IP</span></span><br><span class="line"><span class="string">    设置给request.meta['proxy']</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> defer</span><br><span class="line"><span class="keyword">from</span> twisted.internet.error <span class="keyword">import</span> TimeoutError, DNSLookupError, \</span><br><span class="line">        ConnectionRefusedError, ConnectionDone, ConnectError, \</span><br><span class="line">        ConnectionLost, TCPTimedOutError</span><br><span class="line"><span class="keyword">from</span> twisted.web.client <span class="keyword">import</span> ResponseFailed</span><br><span class="line"><span class="keyword">from</span> scrapy.core.downloader.handlers.http11 <span class="keyword">import</span> TunnelError</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyMiddleware</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    EXCEPTIONS_TO_RETRY = (defer.TimeoutError, TimeoutError, DNSLookupError,</span><br><span class="line">                           ConnectionRefusedError, ConnectionDone, ConnectError,</span><br><span class="line">                           ConnectionLost, TCPTimedOutError, ResponseFailed,</span><br><span class="line">                           IOError, TunnelError)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">         从代理池中获取一个随机的代理IP</span></span><br><span class="line"><span class="string">         设置给request.meta['proxy']</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        response = requests.get(<span class="string">'http://localhost:6868/random?protocol=https&amp;domain=jd.com'</span>)</span><br><span class="line">        request.meta[<span class="string">'proxy'</span>] = response.content.decode()</span><br><span class="line">        request.meta[<span class="string">'dont_redirect'</span>] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span><span class="params">(self, request, exception, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(exception, self.EXCEPTIONS_TO_RETRY):</span><br><span class="line">            <span class="comment"># 获取代理IP</span></span><br><span class="line">            proxy = request.meta[<span class="string">'proxy'</span>]</span><br><span class="line">            <span class="comment"># 提取IP地址</span></span><br><span class="line">            ip = re.findall(<span class="string">'https://(.+):\d+'</span>, proxy)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            params = &#123;</span><br><span class="line">              <span class="string">'ip'</span>: ip,</span><br><span class="line">              <span class="string">'domain'</span>: <span class="string">'jd.com'</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            requests.get(<span class="string">'http://localhost:6868/disable_domain'</span>, params=params)</span><br><span class="line">            <span class="comment"># 构建请求返回</span></span><br><span class="line">            req = request.copy()</span><br><span class="line">            req.dont_filter = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">return</span> req</span><br></pre></td></tr></table></figure><p><strong>在settings.py中开启上面的两个下载器中间件</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置下载器中间件</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line"><span class="string">'mall_spider.middlewares.RandomUserAgent'</span>: <span class="number">500</span>,</span><br><span class="line"><span class="string">'mall_spider.middlewares.ProxyMiddl eware'</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>完整源码请关注微信公众号：ReverseCode，回复：爬虫基础</strong></p></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="mailto:undefined">J</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="http://onejane.github.io/2021/04/09/爬虫基础篇之Scrapy抓取京东/">http://onejane.github.io/2021/04/09/爬虫基础篇之Scrapy抓取京东/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://onejane.github.io">J</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/scrapy/">scrapy</a><a class="post-meta__tags" href="/tags/scrapy-redis/">scrapy_redis</a><a class="post-meta__tags" href="/tags/mongo/">mongo</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="http://onejane.gitee.io/picture/alipay.png"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="http://onejane.gitee.io/picture/wx.png"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="social-share pull-right" data-disabled="google,facebook"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/04/10/hook%E6%8A%93%E5%8C%85trace%E5%AE%9A%E4%BD%8D%E5%AE%9E%E6%88%98/"><i class="fa fa-chevron-left"></i> <span>hook抓包trace定位实战</span></a></div><div class="next-post pull-right"><a href="/2021/04/08/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E4%B9%8B%E6%96%97%E9%B1%BC%E5%BC%B9%E5%B9%95/"><span>爬虫基础篇之斗鱼弹幕</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="vcomment"></div><script src="https://cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify=!1,verify=!1,record_ip=!1,GUEST_INFO=["nick","mail","link"],guest_info="nick,mail,link".split(",").filter(function(i){return-1<GUEST_INFO.indexOf(i)});guest_info=0==guest_info.length?GUEST_INFO:guest_info,window.valine=new Valine({el:"#vcomment",notify:notify,verify:verify,recordIP:record_ip,appId:"cWLsquGr5PNi33OWXNhzerep-gzGzoHsz",appKey:"S35phfCSbm8dAG9LpOc5rjm3",placeholder:"一起来吹牛逼好吗！",avatar:"mm",guest_info:guest_info,pageSize:"10",lang:"zh-cn"})</script></div></div><footer class="footer-bg" style="background-image:url(http://onejane.gitee.io/picture/kali.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2021 By J</div><div class="framework-info"><span>驱动 -</span> <a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 -</span> <a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script src="/js/search/local-search.js"></script><script>/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)&&($("#nav").addClass("is-mobile"),$("footer").addClass("is-mobile"),$("#top-container").addClass("is-mobile"))</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49b1f5">hexo-generator-search</a> <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>